{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-qwDdntU5FOD",
        "outputId": "0689a1ba-7e72-40b7-8016-38ddcdd4c138"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/631.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[91mâ•¸\u001b[0m \u001b[32m624.6/631.1 kB\u001b[0m \u001b[31m41.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m631.1/631.1 kB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/76.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m76.7/76.7 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m178.7/178.7 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m80.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip -q install roboflow ultralytics==8.0.196"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import os\n",
        "from roboflow import Roboflow\n",
        "from ultralytics import YOLO\n",
        "import yaml"
      ],
      "metadata": {
        "id": "g_hwpdO0PYXR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yfOqtM7ugUpl",
        "outputId": "a6512a05-f83c-4af9-cfc0-47bea3756b51"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading Roboflow workspace...\n",
            "loading Roboflow project...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading Dataset Version Zip in Hard-Hat-Universe-26 to yolov8:: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 239920/239920 [00:05<00:00, 42142.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Extracting Dataset Version Zip to Hard-Hat-Universe-26 in yolov8:: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14080/14080 [00:02<00:00, 5226.29it/s]\n"
          ]
        }
      ],
      "source": [
        "rf = Roboflow(api_key=\"#########\")\n",
        "project = rf.workspace(\"universe-datasets\").project(\"hard-hat-universe-0dy7t\")\n",
        "version = project.version(26)\n",
        "dataset = version.download(\"yolov8\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MJZbSLJs5iud",
        "outputId": "f28f6791-b234-4068-bbcd-1507b4086a1e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train size: 4912\n",
            "Valid size: 1414\n",
            "Test size: 708\n"
          ]
        }
      ],
      "source": [
        "assert len(\n",
        "    os.listdir(\"Hard-Hat-Universe-26/train/images\")\n",
        ") == len(os.listdir(\"Hard-Hat-Universe-26/train/labels\"))\n",
        "assert len(\n",
        "    os.listdir(\"Hard-Hat-Universe-26/valid/images\")\n",
        ") == len(os.listdir(\"Hard-Hat-Universe-26/valid/labels\"))\n",
        "assert len(\n",
        "    os.listdir(\"Hard-Hat-Universe-26/test/images\")\n",
        ") == len(os.listdir(\"Hard-Hat-Universe-26/test/labels\"))\n",
        "\n",
        "print(\"Train size:\", len(os.listdir(\"Hard-Hat-Universe-26/train/images\")))\n",
        "print(\"Valid size:\", len(os.listdir(\"Hard-Hat-Universe-26/valid/images\")))\n",
        "print(\"Test size:\", len(os.listdir(\"Hard-Hat-Universe-26/test/images\")))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4MXBkFuw6SbT",
        "outputId": "84ea1514-5abb-4189-eac9-d6310dfdc256"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# Hard Hat Universe > no_nulls_plain\n",
            "https://universe.roboflow.com/universe-datasets/hard-hat-universe-0dy7t\n",
            "\n",
            "Provided by a Roboflow user\n",
            "License: Public Domain\n",
            "\n",
            "# Overview\n",
            "\n",
            "The `Hard Hat` dataset is an object detection dataset of workers in workplace settings that require a hard hat. Annotations also include examples of just \"person\" and \"head,\" for when an individual may be present without a hard hart.\n",
            "\n",
            "Example Image:\n",
            "![Example Image](https://i.imgur.com/7spoIJT.png)\n",
            "\n",
            "# Use Cases\n",
            "\n",
            "One could use this dataset to, for example, build a classifier of workers that are abiding safety code within a workplace versus those that may not be. It is also a good general dataset for practice.\n",
            "\n",
            "# Using this Dataset\n",
            "\n",
            "Use the `fork` button to copy this dataset to your own Roboflow account and export it with new preprocessing settings (perhaps resized for your model's desired format or converted to grayscale), or additional augmentations to make your model generalize better. This particular dataset would be very well suited for Roboflow's new advanced [Bounding Box Only Augmentations](https://blog.roboflow.ai/introducing-bounding-box-level-augmentations/).\n",
            "\n",
            "# About Roboflow\n",
            "\n",
            "[Roboflow](https://roboflow.ai) makes managing, preprocessing, augmenting, and versioning datasets for computer vision seamless.\n",
            "\n",
            "Developers reduce 50% of their code when using Roboflow's workflow, automate annotation quality assurance, save training time, and increase model reproducibility.\n",
            "\n",
            "#### [![Roboflow Workmark](https://i.imgur.com/WHFqYSJ.png =350x)](https://roboflow.ai)\n"
          ]
        }
      ],
      "source": [
        "f = open(\"Hard-Hat-Universe-26/README.dataset.txt\", \"r\")\n",
        "print(f.read())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GszXA5cU5pEX",
        "outputId": "c1cc4f61-6a61-42b1-e676-aa7ea782fffe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['head', 'helmet', 'hi-viz helmet', 'hi-viz vest', 'person']\n"
          ]
        }
      ],
      "source": [
        "with open(\"Hard-Hat-Universe-26/data.yaml\") as stream:\n",
        "    try:\n",
        "        print(yaml.safe_load(stream)[\"names\"])\n",
        "    except yaml.YAMLError as exc:\n",
        "        print(exc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YsAjvL8G6sx1",
        "outputId": "fba974e8-b0ab-4caf-a8e6-6a6e081751d7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 0.43866666666666665 0.472 0.264 0.24\n",
            "1 0.18266666666666667 0.437 0.312 0.274\n",
            "1 0.7906666666666666 0.457 0.38666666666666666 0.338\n",
            "1 0.712 0.351 0.336 0.306\n",
            "4 0.21466666666666667 0.658 0.32266666666666666 0.68\n",
            "4 0.43866666666666665 0.682 0.22133333333333333 0.608\n",
            "4 0.7493333333333333 0.659 0.496 0.674\n",
            "4 0.6333333333333333 0.565 0.34933333333333333 0.694\n"
          ]
        }
      ],
      "source": [
        "file_path = (\n",
        "    \"Hard-Hat-Universe-26/test/labels/\"\n",
        "    \"005304_jpg.rf.dc73a5b2a1b38be45392309595f0bae3.txt\"\n",
        ")\n",
        "\n",
        "with open(file_path, \"r\") as f:\n",
        "    print(f.read())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset cleaning"
      ],
      "metadata": {
        "id": "YTCO0yoDHhRM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XrNG99klKuEr"
      },
      "outputs": [],
      "source": [
        "!mkdir datasets\n",
        "!mv Hard-Hat-Universe-26 datasets/Hard-Hat-Universe-26"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def filter_labels(label_path):\n",
        "    \"\"\"\n",
        "    Rewrites annotation files and filters out any classes\n",
        "    that are not 0 (head) or 1 (helmet).\n",
        "\n",
        "    Args:\n",
        "        label_path (str): A path to the txt annotation file.\n",
        "\n",
        "    Returns:\n",
        "        bool: Returns True if resulting file contains at least 1 label.\n",
        "    \"\"\"\n",
        "    new_lines = []\n",
        "    with open(label_path, \"r\") as file:\n",
        "        lines = file.readlines()\n",
        "        for line in lines:\n",
        "            label_index = int(line.split()[0])\n",
        "            if label_index in {0, 1}:\n",
        "                new_lines.append(line)\n",
        "\n",
        "    with open(label_path, \"w\") as file:\n",
        "        file.writelines(new_lines)\n",
        "\n",
        "    return len(new_lines) > 0\n",
        "\n",
        "\n",
        "dataset_dir = \"datasets/Hard-Hat-Universe-26\"\n",
        "removed_files_cnt = 0\n",
        "\n",
        "for split in [\"train\", \"test\", \"valid\"]:\n",
        "    images_dir = os.path.join(dataset_dir, split, \"images\")\n",
        "    labels_dir = os.path.join(dataset_dir, split, \"labels\")\n",
        "\n",
        "    for label_file in os.listdir(labels_dir):\n",
        "        label_path = os.path.join(labels_dir, label_file)\n",
        "        image_path = os.path.join(images_dir, label_file.replace(\".txt\", \".jpg\"))\n",
        "\n",
        "        bboxes_exist = filter_labels(label_path)\n",
        "        if not bboxes_exist:\n",
        "            # Delete files if there are no bboxes\n",
        "            os.remove(label_path)\n",
        "            os.remove(image_path)\n",
        "            removed_files_cnt += 1\n",
        "\n",
        "print(f\"Deleted {removed_files_cnt} files\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TIZEqoXPHgPu",
        "outputId": "afde511d-8938-4514-8860-1057614dca2d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Deleted 1 files\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training"
      ],
      "metadata": {
        "id": "OSgUtHiEHv8v"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zh5fKPnvIQJU"
      },
      "outputs": [],
      "source": [
        "config = {\n",
        "    \"train\": \"Hard-Hat-Universe-26/train/images\",\n",
        "    \"val\": \"Hard-Hat-Universe-26/valid/images\",\n",
        "    \"test\": \"Hard-Hat-Universe-26/test/images\",\n",
        "    \"nc\": 2,\n",
        "    \"names\": [\"head\", \"helmet\"]\n",
        "}\n",
        "\n",
        "with open(\"yolov8_config.yaml\", \"w\") as file:\n",
        "    yaml.dump(config, file, default_flow_style=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zIekYLo8HWYF",
        "outputId": "fbcfaed3-61ce-4cfb-a452-5eb8a9f382a2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "New https://pypi.org/project/ultralytics/8.2.64 available ğŸ˜ƒ Update with 'pip install -U ultralytics'\n",
            "Ultralytics YOLOv8.0.196 ğŸš€ Python-3.10.12 torch-2.3.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.pt, data=yolov8_config.yaml, epochs=70, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=None, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train2\n",
            "Overriding model.yaml nc=80 with nc=2\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
            " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
            " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 22        [15, 18, 21]  1    751702  ultralytics.nn.modules.head.Detect           [2, [64, 128, 256]]           \n",
            "Model summary: 225 layers, 3011238 parameters, 3011222 gradients, 8.2 GFLOPs\n",
            "\n",
            "Transferred 319/355 items from pretrained weights\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train2', view at http://localhost:6006/\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/datasets/Hard-Hat-Universe-26/train/labels.cache... 4912 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4912/4912 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/datasets/Hard-Hat-Universe-26/valid/labels.cache... 1414 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1414/1414 [00:00<?, ?it/s]\n",
            "Plotting labels to runs/detect/train2/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001667, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/detect/train2\u001b[0m\n",
            "Starting training for 70 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       1/70      2.37G      1.353      1.429      1.107         72        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 307/307 [01:56<00:00,  2.65it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 45/45 [00:15<00:00,  2.90it/s]\n",
            "                   all       1414       5082      0.813       0.83      0.877      0.544\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       2/70      2.19G      1.298     0.9069      1.099        110        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 307/307 [01:52<00:00,  2.72it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 45/45 [00:13<00:00,  3.27it/s]\n",
            "                   all       1414       5082      0.896      0.854      0.911      0.594\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       3/70      2.28G      1.278     0.8146      1.093         95        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 307/307 [01:55<00:00,  2.65it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 45/45 [00:12<00:00,  3.49it/s]\n",
            "                   all       1414       5082      0.875      0.842        0.9      0.579\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       4/70      2.29G       1.27      0.775      1.095         79        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 307/307 [01:56<00:00,  2.63it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 45/45 [00:12<00:00,  3.63it/s]\n",
            "                   all       1414       5082      0.914      0.831       0.91      0.587\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       5/70       2.2G      1.267     0.7402      1.093         97        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 307/307 [01:56<00:00,  2.63it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 45/45 [00:11<00:00,  3.75it/s]\n",
            "                   all       1414       5082      0.918      0.881      0.939      0.612\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       6/70       2.3G      1.245     0.7147       1.09         93        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 307/307 [01:54<00:00,  2.68it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 45/45 [00:11<00:00,  3.82it/s]\n",
            "                   all       1414       5082      0.927      0.894      0.949       0.62\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       7/70      2.28G      1.235      0.689      1.081        113        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 307/307 [01:54<00:00,  2.69it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 45/45 [00:12<00:00,  3.58it/s]\n",
            "                   all       1414       5082      0.912      0.893      0.942      0.611\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       8/70      2.31G      1.224     0.6788      1.075        117        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 307/307 [01:55<00:00,  2.65it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 45/45 [00:11<00:00,  3.76it/s]\n",
            "                   all       1414       5082       0.92      0.898      0.946      0.622\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       9/70      2.25G      1.209     0.6664      1.076        100        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 307/307 [01:54<00:00,  2.67it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 45/45 [00:12<00:00,  3.74it/s]\n",
            "                   all       1414       5082      0.929      0.899      0.951      0.629\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      10/70      2.18G      1.209     0.6434      1.069         76        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 307/307 [01:55<00:00,  2.65it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 45/45 [00:12<00:00,  3.75it/s]\n",
            "                   all       1414       5082      0.919      0.887      0.935      0.614\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      11/70      2.28G      1.201      0.641      1.065        105        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 307/307 [01:54<00:00,  2.69it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 45/45 [00:12<00:00,  3.58it/s]\n",
            "                   all       1414       5082      0.916      0.903      0.951      0.637\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      12/70      2.28G      1.201     0.6358      1.068        118        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 307/307 [01:54<00:00,  2.68it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 45/45 [00:12<00:00,  3.60it/s]\n",
            "                   all       1414       5082      0.912      0.908      0.954      0.631\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      13/70      2.29G      1.193     0.6258      1.065        121        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 307/307 [01:56<00:00,  2.65it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 45/45 [00:12<00:00,  3.47it/s]\n",
            "                   all       1414       5082      0.936      0.896      0.957      0.647\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      14/70       2.3G      1.185     0.6188      1.062        103        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 307/307 [01:52<00:00,  2.73it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 45/45 [00:14<00:00,  3.16it/s]\n",
            "                   all       1414       5082      0.928      0.901      0.954      0.652\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      15/70      2.24G      1.177     0.6142      1.057         69        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 307/307 [01:51<00:00,  2.75it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 45/45 [00:13<00:00,  3.39it/s]\n",
            "                   all       1414       5082      0.936      0.906      0.958      0.645\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      16/70      2.28G      1.175     0.6048      1.055         75        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 307/307 [01:54<00:00,  2.67it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 45/45 [00:11<00:00,  3.78it/s]\n",
            "                   all       1414       5082      0.929      0.912      0.959       0.65\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      17/70      2.18G      1.174     0.6011      1.055        155        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 307/307 [01:54<00:00,  2.69it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 45/45 [00:12<00:00,  3.53it/s]\n",
            "                   all       1414       5082      0.926      0.907      0.957      0.644\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      18/70      2.28G       1.17     0.6016      1.058         90        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 307/307 [01:52<00:00,  2.73it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 45/45 [00:14<00:00,  3.16it/s]\n",
            "                   all       1414       5082      0.934      0.911      0.959      0.645\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      19/70      2.28G      1.163     0.5873      1.056        102        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 307/307 [01:51<00:00,  2.76it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 45/45 [00:14<00:00,  3.12it/s]\n",
            "                   all       1414       5082      0.926       0.92      0.957      0.651\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      20/70       2.3G      1.159     0.5817      1.049         69        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 307/307 [01:51<00:00,  2.76it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 45/45 [00:15<00:00,  2.92it/s]\n",
            "                   all       1414       5082      0.933      0.919       0.96      0.648\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      21/70      2.25G      1.152     0.5784      1.054         98        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 307/307 [01:49<00:00,  2.79it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 45/45 [00:15<00:00,  2.93it/s]\n",
            "                   all       1414       5082      0.925      0.917      0.954      0.647\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      22/70       2.3G      1.149     0.5735       1.05        121        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 307/307 [01:52<00:00,  2.72it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 45/45 [00:16<00:00,  2.80it/s]\n",
            "                   all       1414       5082      0.935      0.914      0.962      0.657\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      23/70      2.31G       1.15     0.5698      1.047         94        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 307/307 [01:52<00:00,  2.73it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 45/45 [00:15<00:00,  2.95it/s]\n",
            "                   all       1414       5082      0.937      0.922      0.958      0.656\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      24/70      2.28G      1.142     0.5686      1.047        127        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 307/307 [01:51<00:00,  2.76it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 45/45 [00:15<00:00,  3.00it/s]\n",
            "                   all       1414       5082      0.934      0.922      0.961      0.662\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      25/70      2.24G      1.139     0.5595      1.042        126        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 307/307 [01:49<00:00,  2.79it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 45/45 [00:15<00:00,  2.93it/s]\n",
            "                   all       1414       5082      0.937      0.919      0.963      0.657\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      26/70       2.3G      1.134     0.5575      1.042         89        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 307/307 [01:53<00:00,  2.71it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 45/45 [00:16<00:00,  2.70it/s]\n",
            "                   all       1414       5082      0.933      0.924      0.963      0.655\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      27/70       2.3G      1.124     0.5519      1.041        101        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 307/307 [01:50<00:00,  2.79it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 45/45 [00:15<00:00,  2.89it/s]\n",
            "                   all       1414       5082      0.935      0.922      0.961      0.657\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      28/70      2.35G      1.128     0.5514       1.04         82        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 307/307 [01:51<00:00,  2.74it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 45/45 [00:14<00:00,  3.21it/s]\n",
            "                   all       1414       5082      0.942      0.919      0.961      0.663\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      29/70       2.2G      1.125     0.5503      1.039         91        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 307/307 [01:53<00:00,  2.70it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 45/45 [00:14<00:00,  3.05it/s]\n",
            "                   all       1414       5082      0.939      0.924      0.964       0.66\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      30/70      2.24G      1.123     0.5415      1.033        106        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 307/307 [01:52<00:00,  2.73it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 45/45 [00:13<00:00,  3.37it/s]\n",
            "                   all       1414       5082      0.935      0.918       0.96       0.66\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      31/70      2.29G      1.113      0.537      1.031        131        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 307/307 [01:53<00:00,  2.70it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 45/45 [00:12<00:00,  3.73it/s]\n",
            "                   all       1414       5082      0.941      0.924      0.963      0.668\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      32/70      2.28G      1.112     0.5383       1.03        132        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 307/307 [01:53<00:00,  2.70it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 45/45 [00:14<00:00,  3.20it/s]\n",
            "                   all       1414       5082      0.941      0.918       0.96      0.662\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      33/70       2.3G      1.113     0.5322      1.031         97        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 307/307 [01:52<00:00,  2.73it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 45/45 [00:14<00:00,  3.01it/s]\n",
            "                   all       1414       5082       0.94      0.918      0.963      0.665\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      34/70       2.3G      1.103     0.5222      1.027         82        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 307/307 [01:52<00:00,  2.73it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 45/45 [00:15<00:00,  2.87it/s]\n",
            "                   all       1414       5082      0.944       0.92      0.964      0.674\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      35/70      2.28G      1.109     0.5278      1.032        104        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 307/307 [01:52<00:00,  2.73it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 45/45 [00:15<00:00,  2.92it/s]\n",
            "                   all       1414       5082      0.942      0.925      0.966       0.67\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      36/70      2.25G      1.097     0.5244      1.028         93        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 307/307 [01:51<00:00,  2.75it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 45/45 [00:15<00:00,  2.90it/s]\n",
            "                   all       1414       5082      0.943      0.925      0.966      0.674\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      37/70       2.3G      1.102     0.5243      1.028        114        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 307/307 [01:52<00:00,  2.74it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 45/45 [00:14<00:00,  3.07it/s]\n",
            "                   all       1414       5082      0.943      0.921      0.962      0.668\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      38/70      2.29G      1.097     0.5224      1.026        140        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 307/307 [01:51<00:00,  2.76it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 45/45 [00:14<00:00,  3.20it/s]\n",
            "                   all       1414       5082      0.938      0.923      0.964      0.667\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      39/70       2.2G      1.096     0.5152      1.027         95        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 307/307 [01:53<00:00,  2.72it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 45/45 [00:15<00:00,  2.99it/s]\n",
            "                   all       1414       5082      0.933      0.929      0.963      0.673\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      40/70       2.3G      1.093     0.5121      1.027        119        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 307/307 [01:53<00:00,  2.71it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 45/45 [00:14<00:00,  3.14it/s]\n",
            "                   all       1414       5082      0.933      0.929      0.961      0.674\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      41/70      2.28G      1.087     0.5081      1.024         81        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 307/307 [01:55<00:00,  2.66it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 45/45 [00:15<00:00,  2.91it/s]\n",
            "                   all       1414       5082      0.934      0.931      0.965       0.67\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      42/70      2.26G      1.078     0.5023      1.022        126        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 307/307 [01:54<00:00,  2.68it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 45/45 [00:15<00:00,  2.92it/s]\n",
            "                   all       1414       5082      0.932      0.933      0.964       0.67\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      43/70      2.24G      1.077     0.5029       1.02         86        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 307/307 [01:57<00:00,  2.61it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 45/45 [00:13<00:00,  3.25it/s]\n",
            "                   all       1414       5082      0.937       0.93      0.962      0.672\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      44/70      2.28G      1.077     0.5021      1.021         98        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 307/307 [01:55<00:00,  2.66it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 45/45 [00:12<00:00,  3.72it/s]\n",
            "                   all       1414       5082      0.941      0.924      0.966      0.678\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      45/70      2.25G      1.069     0.4956      1.014        108        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 307/307 [01:56<00:00,  2.63it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 45/45 [00:12<00:00,  3.64it/s]\n",
            "                   all       1414       5082      0.938      0.927      0.964      0.677\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      46/70       2.3G      1.068     0.4979      1.016         84        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 307/307 [01:57<00:00,  2.61it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 45/45 [00:12<00:00,  3.71it/s]\n",
            "                   all       1414       5082      0.938      0.924      0.962      0.672\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      47/70      2.28G      1.065     0.4893      1.016        133        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 307/307 [01:55<00:00,  2.67it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 45/45 [00:12<00:00,  3.52it/s]\n",
            "                   all       1414       5082      0.937      0.928      0.966      0.676\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      48/70      2.28G      1.058     0.4895      1.016        179        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 307/307 [01:57<00:00,  2.61it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 45/45 [00:12<00:00,  3.63it/s]\n",
            "                   all       1414       5082       0.94      0.928      0.964      0.678\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      49/70      2.21G      1.056     0.4859      1.009        119        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 307/307 [01:57<00:00,  2.61it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 45/45 [00:12<00:00,  3.65it/s]\n",
            "                   all       1414       5082      0.944      0.923      0.962      0.677\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      50/70       2.3G       1.06     0.4866      1.008         80        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 307/307 [01:54<00:00,  2.68it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 45/45 [00:14<00:00,  3.16it/s]\n",
            "                   all       1414       5082      0.938      0.926      0.963       0.68\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      51/70      2.28G      1.054     0.4803      1.007         90        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 307/307 [01:52<00:00,  2.73it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 45/45 [00:15<00:00,  2.94it/s]\n",
            "                   all       1414       5082      0.941      0.924      0.967      0.683\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      52/70       2.3G      1.045     0.4755      1.004        153        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 307/307 [01:52<00:00,  2.72it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 45/45 [00:15<00:00,  2.97it/s]\n",
            "                   all       1414       5082      0.941      0.927      0.968      0.679\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      53/70      2.19G      1.042     0.4743      1.005         93        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 307/307 [01:52<00:00,  2.73it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 45/45 [00:15<00:00,  2.95it/s]\n",
            "                   all       1414       5082      0.937       0.93      0.966      0.681\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      54/70      2.24G      1.044     0.4734      1.005         93        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 307/307 [01:52<00:00,  2.72it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 45/45 [00:13<00:00,  3.23it/s]\n",
            "                   all       1414       5082       0.94       0.93      0.967      0.678\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      55/70      2.28G      1.038     0.4659      1.003        110        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 307/307 [01:53<00:00,  2.71it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 45/45 [00:16<00:00,  2.81it/s]\n",
            "                   all       1414       5082      0.946      0.923      0.967      0.679\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      56/70      2.29G      1.038     0.4705      1.003        120        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 307/307 [01:50<00:00,  2.77it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 45/45 [00:15<00:00,  2.86it/s]\n",
            "                   all       1414       5082      0.941      0.929      0.967      0.681\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      57/70      2.28G      1.034     0.4659      1.002         85        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 307/307 [01:50<00:00,  2.79it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 45/45 [00:15<00:00,  2.88it/s]\n",
            "                   all       1414       5082      0.947      0.924      0.964       0.68\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      58/70      2.26G      1.029     0.4618     0.9977         87        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 307/307 [01:52<00:00,  2.73it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 45/45 [00:15<00:00,  2.93it/s]\n",
            "                   all       1414       5082      0.945      0.924      0.965      0.677\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      59/70      2.24G      1.026      0.462     0.9974        121        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 307/307 [01:53<00:00,  2.70it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 45/45 [00:16<00:00,  2.74it/s]\n",
            "                   all       1414       5082      0.947      0.924      0.967      0.682\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      60/70      2.24G       1.02     0.4636     0.9976        110        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 307/307 [01:52<00:00,  2.72it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 45/45 [00:15<00:00,  2.83it/s]\n",
            "                   all       1414       5082       0.94      0.928      0.966       0.68\n",
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      61/70      2.44G      1.011     0.4158      1.002         61        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 307/307 [01:47<00:00,  2.86it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 45/45 [00:11<00:00,  3.78it/s]\n",
            "                   all       1414       5082      0.936       0.93      0.965      0.679\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      62/70      2.27G          1     0.4102     0.9964         82        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 307/307 [01:43<00:00,  2.98it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 45/45 [00:14<00:00,  3.01it/s]\n",
            "                   all       1414       5082       0.94      0.928      0.968      0.684\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      63/70       2.3G     0.9986     0.4072     0.9966         52        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 307/307 [01:44<00:00,  2.93it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 45/45 [00:15<00:00,  2.99it/s]\n",
            "                   all       1414       5082      0.936      0.933      0.965      0.682\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      64/70      2.29G      0.991     0.4039     0.9917         72        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 307/307 [01:40<00:00,  3.04it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 45/45 [00:12<00:00,  3.48it/s]\n",
            "                   all       1414       5082      0.941      0.924      0.967      0.683\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      65/70      2.28G     0.9878     0.4012     0.9914         63        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 307/307 [01:44<00:00,  2.94it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 45/45 [00:15<00:00,  2.90it/s]\n",
            "                   all       1414       5082      0.941      0.924      0.967      0.685\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      66/70       2.3G     0.9786     0.3977     0.9908         51        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 307/307 [01:45<00:00,  2.92it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 45/45 [00:11<00:00,  3.81it/s]\n",
            "                   all       1414       5082      0.941      0.924      0.967      0.685\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      67/70       2.3G     0.9782     0.3972     0.9902         76        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 307/307 [01:44<00:00,  2.95it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 45/45 [00:16<00:00,  2.81it/s]\n",
            "                   all       1414       5082       0.94      0.923      0.966      0.686\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      68/70      2.17G     0.9751     0.3953     0.9886         42        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 307/307 [01:42<00:00,  2.98it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 45/45 [00:13<00:00,  3.22it/s]\n",
            "                   all       1414       5082      0.934      0.932      0.966      0.685\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      69/70      2.29G     0.9682     0.3903     0.9849         58        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 307/307 [01:42<00:00,  2.99it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 45/45 [00:15<00:00,  2.92it/s]\n",
            "                   all       1414       5082      0.944      0.922      0.967      0.686\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      70/70       2.3G     0.9727      0.393     0.9848         51        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 307/307 [01:44<00:00,  2.93it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 45/45 [00:13<00:00,  3.25it/s]\n",
            "                   all       1414       5082      0.943      0.921      0.966      0.686\n",
            "\n",
            "70 epochs completed in 2.474 hours.\n",
            "Optimizer stripped from runs/detect/train2/weights/last.pt, 6.2MB\n",
            "Optimizer stripped from runs/detect/train2/weights/best.pt, 6.2MB\n",
            "\n",
            "Validating runs/detect/train2/weights/best.pt...\n",
            "Ultralytics YOLOv8.0.196 ğŸš€ Python-3.10.12 torch-2.3.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "Model summary (fused): 168 layers, 3006038 parameters, 0 gradients, 8.1 GFLOPs\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 45/45 [00:20<00:00,  2.19it/s]\n",
            "                   all       1414       5082      0.944      0.922      0.967      0.687\n",
            "                  head       1414       1168      0.924      0.911      0.956       0.68\n",
            "                helmet       1414       3914      0.964      0.934      0.978      0.693\n",
            "Speed: 0.2ms preprocess, 2.0ms inference, 0.0ms loss, 1.7ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/train2\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ultralytics.utils.metrics.DetMetrics object with attributes:\n",
              "\n",
              "ap_class_index: array([0, 1])\n",
              "box: ultralytics.utils.metrics.Metric object\n",
              "confusion_matrix: <ultralytics.utils.metrics.ConfusionMatrix object at 0x7988e6a97250>\n",
              "fitness: 0.7146550101618692\n",
              "keys: ['metrics/precision(B)', 'metrics/recall(B)', 'metrics/mAP50(B)', 'metrics/mAP50-95(B)']\n",
              "maps: array([    0.67976,     0.69348])\n",
              "names: {0: 'head', 1: 'helmet'}\n",
              "plot: True\n",
              "results_dict: {'metrics/precision(B)': 0.9436547591868141, 'metrics/recall(B)': 0.9223755765901628, 'metrics/mAP50(B)': 0.9669594604461744, 'metrics/mAP50-95(B)': 0.6866211823525019, 'fitness': 0.7146550101618692}\n",
              "save_dir: PosixPath('runs/detect/train2')\n",
              "speed: {'preprocess': 0.20671093143533278, 'inference': 1.9575200627177238, 'loss': 0.000611390217696086, 'postprocess': 1.6500782932891198}"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "model = YOLO(\"yolov8n.pt\")\n",
        "model.train(data=\"yolov8_config.yaml\", epochs=70)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prediction"
      ],
      "metadata": {
        "id": "WhJ8xpbKHznP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fx4CwkU_ga6e"
      },
      "outputs": [],
      "source": [
        "model_trained = YOLO(\"/content/runs/detect/train2/weights/best.pt\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def draw_boxes(frame, detections, class_counts, class_colors):\n",
        "    \"\"\"\n",
        "    Draws bboxes and class counter.\n",
        "\n",
        "    Args:\n",
        "        frame (np.ndarray): Input frame.\n",
        "        detections (list[tuple[torch.Tensor]]): Predicted bboxes parameters.\n",
        "        class_counts (list[int]): Class counter on the input frame.\n",
        "        class_colors (dict[int: tuple[int]]): Class colormap.\n",
        "\n",
        "    Returns:\n",
        "        np.ndarray: Resulting frame with bboxes.\n",
        "    \"\"\"\n",
        "    class_names = {\n",
        "        \"head\": \"person\",\n",
        "        \"helmet\": \"helmet\"\n",
        "    }\n",
        "\n",
        "    for det in detections:\n",
        "        x1, y1, x2, y2, conf, cls = det\n",
        "        label = f\"{model_trained.names[int(cls)]} {conf:.2f}\"\n",
        "        label_name = label.split()[0]\n",
        "        label_conf = label.split()[1]\n",
        "        color = class_colors[int(cls)]\n",
        "        # bbox\n",
        "        cv2.rectangle(frame, (int(x1), int(y1)), (int(x2), int(y2)), color, 2)\n",
        "        # text background\n",
        "        (w, h), _ = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.8, 2)\n",
        "        cv2.rectangle(frame,\n",
        "                      (int(x1), int(y1) - h - 10), (int(x1) + w, int(y1)),\n",
        "                      color, -1)\n",
        "        # text\n",
        "        cv2.putText(frame, f\"{class_names[label_name]} {label_conf}\",\n",
        "                    (int(x1), int(y1) - 5),\n",
        "                    cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 2)\n",
        "\n",
        "    overlay = frame.copy()\n",
        "    alpha = 0.6\n",
        "    cv2.rectangle(overlay, (0, 0), (180, 70), (0, 0, 0), -1)\n",
        "    cv2.addWeighted(overlay, alpha, frame, 1 - alpha, 0, frame)\n",
        "    cv2.putText(frame, f\"Person: {class_counts[0]}\", (10, 30),\n",
        "                cv2.FONT_HERSHEY_SIMPLEX, 1, class_colors[0], 2)\n",
        "    cv2.putText(frame, f\"Helmet: {class_counts[1]}\", (10, 60),\n",
        "                cv2.FONT_HERSHEY_SIMPLEX, 1, class_colors[1], 2)\n",
        "\n",
        "    return frame\n",
        "\n",
        "\n",
        "input_video_path = \"workers_1.mp4\"\n",
        "output_video_path = \"workers_1_annotated.mp4\"\n",
        "cap = cv2.VideoCapture(input_video_path)\n",
        "\n",
        "fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
        "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\n",
        "out = cv2.VideoWriter(output_video_path, fourcc, fps, (width, height))\n",
        "\n",
        "class_colormap = {\n",
        "    0: (242, 174, 113),\n",
        "    1: (69, 86, 234)\n",
        "}\n",
        "\n",
        "while cap.isOpened():\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    results = model_trained(frame, conf=0.4)\n",
        "    class_counts = [0, 0]  # [head_count, helmet_count]\n",
        "    detections = []\n",
        "    for result in results:\n",
        "        for *box, conf, cls in result.boxes.data:\n",
        "            detections.append((*box, conf, cls))\n",
        "            class_counts[int(cls)] += 1\n",
        "\n",
        "    frame = draw_boxes(frame, detections, class_counts, class_colormap)\n",
        "    out.write(frame)\n",
        "\n",
        "cap.release()\n",
        "out.release()\n",
        "cv2.destroyAllWindows()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sYObLBtQ3Ro5",
        "outputId": "f4c07350-6a60-43aa-90ec-ae16dc90813a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "0: 384x640 1 head, 3 helmets, 24.6ms\n",
            "Speed: 3.3ms preprocess, 24.6ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 head, 3 helmets, 11.4ms\n",
            "Speed: 3.1ms preprocess, 11.4ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 head, 3 helmets, 9.7ms\n",
            "Speed: 3.4ms preprocess, 9.7ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 head, 4 helmets, 21.0ms\n",
            "Speed: 5.4ms preprocess, 21.0ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 8.7ms\n",
            "Speed: 2.7ms preprocess, 8.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 7.8ms\n",
            "Speed: 2.9ms preprocess, 7.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 8.5ms\n",
            "Speed: 2.9ms preprocess, 8.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 9.3ms\n",
            "Speed: 3.4ms preprocess, 9.3ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 9.1ms\n",
            "Speed: 3.2ms preprocess, 9.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 8.0ms\n",
            "Speed: 3.0ms preprocess, 8.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 7.7ms\n",
            "Speed: 3.0ms preprocess, 7.7ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 11.0ms\n",
            "Speed: 3.9ms preprocess, 11.0ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 9.6ms\n",
            "Speed: 2.8ms preprocess, 9.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 8.5ms\n",
            "Speed: 3.0ms preprocess, 8.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 8.3ms\n",
            "Speed: 2.9ms preprocess, 8.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 10.0ms\n",
            "Speed: 2.8ms preprocess, 10.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 7.9ms\n",
            "Speed: 5.5ms preprocess, 7.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 8.0ms\n",
            "Speed: 2.9ms preprocess, 8.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 9.7ms\n",
            "Speed: 3.1ms preprocess, 9.7ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 9.6ms\n",
            "Speed: 3.0ms preprocess, 9.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 7.4ms\n",
            "Speed: 2.8ms preprocess, 7.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 8.0ms\n",
            "Speed: 2.9ms preprocess, 8.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 8.6ms\n",
            "Speed: 3.0ms preprocess, 8.6ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 14.8ms\n",
            "Speed: 3.0ms preprocess, 14.8ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 helmets, 12.5ms\n",
            "Speed: 3.5ms preprocess, 12.5ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 13.4ms\n",
            "Speed: 3.0ms preprocess, 13.4ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 12.8ms\n",
            "Speed: 7.3ms preprocess, 12.8ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 10.5ms\n",
            "Speed: 3.5ms preprocess, 10.5ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 11.2ms\n",
            "Speed: 4.0ms preprocess, 11.2ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 17.2ms\n",
            "Speed: 2.8ms preprocess, 17.2ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 8.1ms\n",
            "Speed: 3.7ms preprocess, 8.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 11.5ms\n",
            "Speed: 3.0ms preprocess, 11.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 8.1ms\n",
            "Speed: 3.1ms preprocess, 8.1ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 8.2ms\n",
            "Speed: 3.0ms preprocess, 8.2ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 9.1ms\n",
            "Speed: 3.6ms preprocess, 9.1ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 13.7ms\n",
            "Speed: 3.2ms preprocess, 13.7ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 8.2ms\n",
            "Speed: 3.0ms preprocess, 8.2ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 8.3ms\n",
            "Speed: 3.1ms preprocess, 8.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 9.3ms\n",
            "Speed: 3.3ms preprocess, 9.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 8.0ms\n",
            "Speed: 2.9ms preprocess, 8.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 8.1ms\n",
            "Speed: 2.9ms preprocess, 8.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 9.2ms\n",
            "Speed: 3.0ms preprocess, 9.2ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 11.1ms\n",
            "Speed: 2.9ms preprocess, 11.1ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 11.6ms\n",
            "Speed: 3.0ms preprocess, 11.6ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 13.2ms\n",
            "Speed: 2.9ms preprocess, 13.2ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 11.2ms\n",
            "Speed: 3.0ms preprocess, 11.2ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 11.4ms\n",
            "Speed: 3.0ms preprocess, 11.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 10.1ms\n",
            "Speed: 2.8ms preprocess, 10.1ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 10.7ms\n",
            "Speed: 2.8ms preprocess, 10.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 9.0ms\n",
            "Speed: 2.8ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 8.3ms\n",
            "Speed: 3.0ms preprocess, 8.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 8.8ms\n",
            "Speed: 2.9ms preprocess, 8.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 7.3ms\n",
            "Speed: 3.0ms preprocess, 7.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 8.2ms\n",
            "Speed: 2.9ms preprocess, 8.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 8.3ms\n",
            "Speed: 3.0ms preprocess, 8.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 8.1ms\n",
            "Speed: 2.8ms preprocess, 8.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 7.7ms\n",
            "Speed: 2.9ms preprocess, 7.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 9.3ms\n",
            "Speed: 2.8ms preprocess, 9.3ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 8.2ms\n",
            "Speed: 2.9ms preprocess, 8.2ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 8.4ms\n",
            "Speed: 2.9ms preprocess, 8.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 8.7ms\n",
            "Speed: 2.8ms preprocess, 8.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 8.1ms\n",
            "Speed: 2.9ms preprocess, 8.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 7.9ms\n",
            "Speed: 3.1ms preprocess, 7.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 12.5ms\n",
            "Speed: 3.4ms preprocess, 12.5ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 15.5ms\n",
            "Speed: 5.2ms preprocess, 15.5ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 9.8ms\n",
            "Speed: 4.6ms preprocess, 9.8ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 11.9ms\n",
            "Speed: 3.6ms preprocess, 11.9ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 11.7ms\n",
            "Speed: 3.5ms preprocess, 11.7ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 10.6ms\n",
            "Speed: 3.3ms preprocess, 10.6ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 9.3ms\n",
            "Speed: 3.1ms preprocess, 9.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 7.8ms\n",
            "Speed: 3.0ms preprocess, 7.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 10.2ms\n",
            "Speed: 2.8ms preprocess, 10.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 9.2ms\n",
            "Speed: 2.8ms preprocess, 9.2ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 7.7ms\n",
            "Speed: 2.9ms preprocess, 7.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 8.6ms\n",
            "Speed: 2.9ms preprocess, 8.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 8.2ms\n",
            "Speed: 3.0ms preprocess, 8.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 8.3ms\n",
            "Speed: 3.2ms preprocess, 8.3ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 9.2ms\n",
            "Speed: 2.9ms preprocess, 9.2ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 8.3ms\n",
            "Speed: 2.9ms preprocess, 8.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 9.7ms\n",
            "Speed: 2.8ms preprocess, 9.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 12.4ms\n",
            "Speed: 3.0ms preprocess, 12.4ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 7.5ms\n",
            "Speed: 3.0ms preprocess, 7.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 9.9ms\n",
            "Speed: 3.4ms preprocess, 9.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 11.8ms\n",
            "Speed: 3.2ms preprocess, 11.8ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 10.3ms\n",
            "Speed: 2.8ms preprocess, 10.3ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 10.8ms\n",
            "Speed: 2.9ms preprocess, 10.8ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 16.8ms\n",
            "Speed: 3.0ms preprocess, 16.8ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 10.3ms\n",
            "Speed: 4.3ms preprocess, 10.3ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 8.5ms\n",
            "Speed: 3.2ms preprocess, 8.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 8.5ms\n",
            "Speed: 3.0ms preprocess, 8.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 9.7ms\n",
            "Speed: 3.1ms preprocess, 9.7ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 9.0ms\n",
            "Speed: 3.0ms preprocess, 9.0ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 head, 3 helmets, 8.1ms\n",
            "Speed: 3.0ms preprocess, 8.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 head, 3 helmets, 9.2ms\n",
            "Speed: 3.5ms preprocess, 9.2ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 10.3ms\n",
            "Speed: 3.1ms preprocess, 10.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 helmets, 8.4ms\n",
            "Speed: 4.0ms preprocess, 8.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 head, 3 helmets, 7.7ms\n",
            "Speed: 3.0ms preprocess, 7.7ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 head, 3 helmets, 7.4ms\n",
            "Speed: 2.9ms preprocess, 7.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 head, 3 helmets, 8.2ms\n",
            "Speed: 3.1ms preprocess, 8.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 head, 3 helmets, 11.3ms\n",
            "Speed: 3.3ms preprocess, 11.3ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 head, 3 helmets, 13.3ms\n",
            "Speed: 6.4ms preprocess, 13.3ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 head, 3 helmets, 12.7ms\n",
            "Speed: 3.1ms preprocess, 12.7ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 head, 3 helmets, 11.7ms\n",
            "Speed: 3.1ms preprocess, 11.7ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 head, 3 helmets, 11.4ms\n",
            "Speed: 3.2ms preprocess, 11.4ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 heads, 3 helmets, 11.9ms\n",
            "Speed: 3.1ms preprocess, 11.9ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 head, 3 helmets, 10.1ms\n",
            "Speed: 5.7ms preprocess, 10.1ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 head, 3 helmets, 9.3ms\n",
            "Speed: 3.0ms preprocess, 9.3ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 head, 3 helmets, 12.7ms\n",
            "Speed: 3.1ms preprocess, 12.7ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 head, 3 helmets, 9.3ms\n",
            "Speed: 3.3ms preprocess, 9.3ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 head, 3 helmets, 9.7ms\n",
            "Speed: 3.1ms preprocess, 9.7ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 head, 3 helmets, 9.6ms\n",
            "Speed: 3.4ms preprocess, 9.6ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 head, 3 helmets, 10.0ms\n",
            "Speed: 3.0ms preprocess, 10.0ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 head, 3 helmets, 9.5ms\n",
            "Speed: 3.2ms preprocess, 9.5ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 head, 3 helmets, 10.1ms\n",
            "Speed: 3.3ms preprocess, 10.1ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 head, 3 helmets, 9.7ms\n",
            "Speed: 3.4ms preprocess, 9.7ms inference, 5.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 head, 3 helmets, 11.1ms\n",
            "Speed: 3.3ms preprocess, 11.1ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 head, 3 helmets, 10.9ms\n",
            "Speed: 3.3ms preprocess, 10.9ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 head, 3 helmets, 8.7ms\n",
            "Speed: 3.3ms preprocess, 8.7ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 head, 3 helmets, 24.1ms\n",
            "Speed: 3.0ms preprocess, 24.1ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 head, 3 helmets, 8.9ms\n",
            "Speed: 8.7ms preprocess, 8.9ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 head, 3 helmets, 16.2ms\n",
            "Speed: 5.1ms preprocess, 16.2ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 9.0ms\n",
            "Speed: 3.4ms preprocess, 9.0ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 13.6ms\n",
            "Speed: 3.6ms preprocess, 13.6ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 14.9ms\n",
            "Speed: 3.1ms preprocess, 14.9ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 15.1ms\n",
            "Speed: 3.1ms preprocess, 15.1ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 20.2ms\n",
            "Speed: 3.1ms preprocess, 20.2ms inference, 4.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 16.6ms\n",
            "Speed: 3.1ms preprocess, 16.6ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 11.9ms\n",
            "Speed: 3.0ms preprocess, 11.9ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 14.2ms\n",
            "Speed: 3.1ms preprocess, 14.2ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 15.8ms\n",
            "Speed: 3.0ms preprocess, 15.8ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 15.4ms\n",
            "Speed: 3.7ms preprocess, 15.4ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 15.4ms\n",
            "Speed: 3.7ms preprocess, 15.4ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 16.9ms\n",
            "Speed: 2.9ms preprocess, 16.9ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 11.2ms\n",
            "Speed: 4.3ms preprocess, 11.2ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 13.4ms\n",
            "Speed: 3.0ms preprocess, 13.4ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 10.6ms\n",
            "Speed: 8.2ms preprocess, 10.6ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 10.1ms\n",
            "Speed: 2.9ms preprocess, 10.1ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 11.4ms\n",
            "Speed: 3.0ms preprocess, 11.4ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 15.4ms\n",
            "Speed: 3.0ms preprocess, 15.4ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 10.2ms\n",
            "Speed: 3.0ms preprocess, 10.2ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 10.4ms\n",
            "Speed: 3.0ms preprocess, 10.4ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 10.6ms\n",
            "Speed: 4.3ms preprocess, 10.6ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 20.1ms\n",
            "Speed: 3.5ms preprocess, 20.1ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 12.9ms\n",
            "Speed: 3.4ms preprocess, 12.9ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 17.9ms\n",
            "Speed: 3.0ms preprocess, 17.9ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 23.8ms\n",
            "Speed: 4.6ms preprocess, 23.8ms inference, 6.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 16.9ms\n",
            "Speed: 3.7ms preprocess, 16.9ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 10.2ms\n",
            "Speed: 3.0ms preprocess, 10.2ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 17.2ms\n",
            "Speed: 3.6ms preprocess, 17.2ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 11.9ms\n",
            "Speed: 3.7ms preprocess, 11.9ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 12.5ms\n",
            "Speed: 3.3ms preprocess, 12.5ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 11.4ms\n",
            "Speed: 3.3ms preprocess, 11.4ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 11.3ms\n",
            "Speed: 3.3ms preprocess, 11.3ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 15.6ms\n",
            "Speed: 7.0ms preprocess, 15.6ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 13.1ms\n",
            "Speed: 2.9ms preprocess, 13.1ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 12.5ms\n",
            "Speed: 3.2ms preprocess, 12.5ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 13.5ms\n",
            "Speed: 4.2ms preprocess, 13.5ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 14.5ms\n",
            "Speed: 5.3ms preprocess, 14.5ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 14.7ms\n",
            "Speed: 3.1ms preprocess, 14.7ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 10.2ms\n",
            "Speed: 2.9ms preprocess, 10.2ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 10.6ms\n",
            "Speed: 3.0ms preprocess, 10.6ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 10.6ms\n",
            "Speed: 4.8ms preprocess, 10.6ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 15.6ms\n",
            "Speed: 3.0ms preprocess, 15.6ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 11.2ms\n",
            "Speed: 5.5ms preprocess, 11.2ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 13.4ms\n",
            "Speed: 5.8ms preprocess, 13.4ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 12.7ms\n",
            "Speed: 10.1ms preprocess, 12.7ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 15.5ms\n",
            "Speed: 3.5ms preprocess, 15.5ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 12.0ms\n",
            "Speed: 5.1ms preprocess, 12.0ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 10.1ms\n",
            "Speed: 2.8ms preprocess, 10.1ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 10.3ms\n",
            "Speed: 2.9ms preprocess, 10.3ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 21.8ms\n",
            "Speed: 5.2ms preprocess, 21.8ms inference, 7.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 12.3ms\n",
            "Speed: 3.0ms preprocess, 12.3ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 13.0ms\n",
            "Speed: 2.9ms preprocess, 13.0ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 10.4ms\n",
            "Speed: 2.8ms preprocess, 10.4ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 10.5ms\n",
            "Speed: 4.9ms preprocess, 10.5ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 10.5ms\n",
            "Speed: 2.9ms preprocess, 10.5ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 10.5ms\n",
            "Speed: 2.8ms preprocess, 10.5ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 13.8ms\n",
            "Speed: 3.9ms preprocess, 13.8ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 11.4ms\n",
            "Speed: 3.0ms preprocess, 11.4ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 10.7ms\n",
            "Speed: 5.1ms preprocess, 10.7ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 11.6ms\n",
            "Speed: 3.1ms preprocess, 11.6ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 10.2ms\n",
            "Speed: 4.5ms preprocess, 10.2ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 13.7ms\n",
            "Speed: 2.8ms preprocess, 13.7ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 13.1ms\n",
            "Speed: 3.0ms preprocess, 13.1ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 12.7ms\n",
            "Speed: 6.1ms preprocess, 12.7ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 12.5ms\n",
            "Speed: 3.0ms preprocess, 12.5ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 15.1ms\n",
            "Speed: 3.8ms preprocess, 15.1ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 13.2ms\n",
            "Speed: 4.9ms preprocess, 13.2ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 13.7ms\n",
            "Speed: 3.0ms preprocess, 13.7ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 10.4ms\n",
            "Speed: 3.4ms preprocess, 10.4ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 11.4ms\n",
            "Speed: 2.9ms preprocess, 11.4ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 17.8ms\n",
            "Speed: 3.0ms preprocess, 17.8ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 17.3ms\n",
            "Speed: 3.0ms preprocess, 17.3ms inference, 8.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 14.4ms\n",
            "Speed: 2.9ms preprocess, 14.4ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 15.0ms\n",
            "Speed: 4.5ms preprocess, 15.0ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 10.6ms\n",
            "Speed: 3.3ms preprocess, 10.6ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 10.4ms\n",
            "Speed: 2.9ms preprocess, 10.4ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 11.6ms\n",
            "Speed: 4.1ms preprocess, 11.6ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 16.4ms\n",
            "Speed: 6.0ms preprocess, 16.4ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 12.9ms\n",
            "Speed: 5.0ms preprocess, 12.9ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 11.8ms\n",
            "Speed: 2.8ms preprocess, 11.8ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 10.0ms\n",
            "Speed: 5.0ms preprocess, 10.0ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 13.6ms\n",
            "Speed: 3.0ms preprocess, 13.6ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 11.9ms\n",
            "Speed: 3.0ms preprocess, 11.9ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 11.4ms\n",
            "Speed: 3.0ms preprocess, 11.4ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 10.1ms\n",
            "Speed: 2.9ms preprocess, 10.1ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 12.8ms\n",
            "Speed: 8.9ms preprocess, 12.8ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 13.4ms\n",
            "Speed: 6.0ms preprocess, 13.4ms inference, 7.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 10.2ms\n",
            "Speed: 3.9ms preprocess, 10.2ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 10.7ms\n",
            "Speed: 2.9ms preprocess, 10.7ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 12.7ms\n",
            "Speed: 3.0ms preprocess, 12.7ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 13.3ms\n",
            "Speed: 7.0ms preprocess, 13.3ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 12.3ms\n",
            "Speed: 3.1ms preprocess, 12.3ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 9.8ms\n",
            "Speed: 2.9ms preprocess, 9.8ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 14.4ms\n",
            "Speed: 2.9ms preprocess, 14.4ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 13.8ms\n",
            "Speed: 3.0ms preprocess, 13.8ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 11.6ms\n",
            "Speed: 3.0ms preprocess, 11.6ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 11.2ms\n",
            "Speed: 2.9ms preprocess, 11.2ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 11.9ms\n",
            "Speed: 2.9ms preprocess, 11.9ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 10.4ms\n",
            "Speed: 2.8ms preprocess, 10.4ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 14.5ms\n",
            "Speed: 3.7ms preprocess, 14.5ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 11.8ms\n",
            "Speed: 2.9ms preprocess, 11.8ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 10.4ms\n",
            "Speed: 7.9ms preprocess, 10.4ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 11.5ms\n",
            "Speed: 3.4ms preprocess, 11.5ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 28.5ms\n",
            "Speed: 4.6ms preprocess, 28.5ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 12.5ms\n",
            "Speed: 3.2ms preprocess, 12.5ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 17.0ms\n",
            "Speed: 4.3ms preprocess, 17.0ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 22.9ms\n",
            "Speed: 3.4ms preprocess, 22.9ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 11.9ms\n",
            "Speed: 2.9ms preprocess, 11.9ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 9.7ms\n",
            "Speed: 3.2ms preprocess, 9.7ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 11.3ms\n",
            "Speed: 2.9ms preprocess, 11.3ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 9.7ms\n",
            "Speed: 3.0ms preprocess, 9.7ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 12.1ms\n",
            "Speed: 2.9ms preprocess, 12.1ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 10.2ms\n",
            "Speed: 4.1ms preprocess, 10.2ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 11.7ms\n",
            "Speed: 2.9ms preprocess, 11.7ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 18.9ms\n",
            "Speed: 3.0ms preprocess, 18.9ms inference, 4.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 13.9ms\n",
            "Speed: 3.2ms preprocess, 13.9ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 15.2ms\n",
            "Speed: 3.6ms preprocess, 15.2ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 14.2ms\n",
            "Speed: 2.9ms preprocess, 14.2ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 19.0ms\n",
            "Speed: 3.2ms preprocess, 19.0ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 14.6ms\n",
            "Speed: 2.9ms preprocess, 14.6ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 12.4ms\n",
            "Speed: 3.3ms preprocess, 12.4ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 12.2ms\n",
            "Speed: 9.3ms preprocess, 12.2ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 10.2ms\n",
            "Speed: 2.8ms preprocess, 10.2ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 10.8ms\n",
            "Speed: 5.7ms preprocess, 10.8ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 12.3ms\n",
            "Speed: 2.9ms preprocess, 12.3ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 14.0ms\n",
            "Speed: 4.4ms preprocess, 14.0ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 29.7ms\n",
            "Speed: 5.3ms preprocess, 29.7ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 16.7ms\n",
            "Speed: 3.1ms preprocess, 16.7ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 9.7ms\n",
            "Speed: 3.0ms preprocess, 9.7ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 8.8ms\n",
            "Speed: 3.3ms preprocess, 8.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 11.7ms\n",
            "Speed: 3.0ms preprocess, 11.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 11.7ms\n",
            "Speed: 3.1ms preprocess, 11.7ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 13.4ms\n",
            "Speed: 3.2ms preprocess, 13.4ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 12.1ms\n",
            "Speed: 4.1ms preprocess, 12.1ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 13.5ms\n",
            "Speed: 3.3ms preprocess, 13.5ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 9.3ms\n",
            "Speed: 3.0ms preprocess, 9.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 10.8ms\n",
            "Speed: 3.1ms preprocess, 10.8ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 10.3ms\n",
            "Speed: 3.2ms preprocess, 10.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 10.1ms\n",
            "Speed: 3.7ms preprocess, 10.1ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 11.9ms\n",
            "Speed: 3.0ms preprocess, 11.9ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 10.7ms\n",
            "Speed: 2.8ms preprocess, 10.7ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 8.0ms\n",
            "Speed: 3.6ms preprocess, 8.0ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 9.9ms\n",
            "Speed: 3.0ms preprocess, 9.9ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 10.7ms\n",
            "Speed: 3.0ms preprocess, 10.7ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 10.2ms\n",
            "Speed: 3.1ms preprocess, 10.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 9.9ms\n",
            "Speed: 3.8ms preprocess, 9.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 10.0ms\n",
            "Speed: 3.9ms preprocess, 10.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 10.6ms\n",
            "Speed: 5.7ms preprocess, 10.6ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 11.4ms\n",
            "Speed: 3.0ms preprocess, 11.4ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 12.9ms\n",
            "Speed: 3.3ms preprocess, 12.9ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 19.7ms\n",
            "Speed: 4.6ms preprocess, 19.7ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 25.7ms\n",
            "Speed: 4.0ms preprocess, 25.7ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 11.7ms\n",
            "Speed: 3.3ms preprocess, 11.7ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 13.1ms\n",
            "Speed: 3.1ms preprocess, 13.1ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 11.5ms\n",
            "Speed: 3.1ms preprocess, 11.5ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 14.1ms\n",
            "Speed: 3.0ms preprocess, 14.1ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 9.6ms\n",
            "Speed: 3.9ms preprocess, 9.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 8.0ms\n",
            "Speed: 3.0ms preprocess, 8.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 8.9ms\n",
            "Speed: 2.9ms preprocess, 8.9ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 10.4ms\n",
            "Speed: 3.1ms preprocess, 10.4ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 9.5ms\n",
            "Speed: 3.3ms preprocess, 9.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 9.3ms\n",
            "Speed: 3.0ms preprocess, 9.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 10.3ms\n",
            "Speed: 3.3ms preprocess, 10.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 10.3ms\n",
            "Speed: 2.9ms preprocess, 10.3ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 10.6ms\n",
            "Speed: 3.4ms preprocess, 10.6ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 9.3ms\n",
            "Speed: 3.0ms preprocess, 9.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 13.1ms\n",
            "Speed: 3.2ms preprocess, 13.1ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 10.2ms\n",
            "Speed: 3.5ms preprocess, 10.2ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 15.3ms\n",
            "Speed: 3.0ms preprocess, 15.3ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 12.8ms\n",
            "Speed: 3.0ms preprocess, 12.8ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 13.6ms\n",
            "Speed: 4.3ms preprocess, 13.6ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 12.6ms\n",
            "Speed: 3.3ms preprocess, 12.6ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 9.1ms\n",
            "Speed: 3.6ms preprocess, 9.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 9.5ms\n",
            "Speed: 3.5ms preprocess, 9.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 8.7ms\n",
            "Speed: 3.6ms preprocess, 8.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 11.4ms\n",
            "Speed: 4.3ms preprocess, 11.4ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 10.5ms\n",
            "Speed: 3.0ms preprocess, 10.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 11.2ms\n",
            "Speed: 3.3ms preprocess, 11.2ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 8.2ms\n",
            "Speed: 2.9ms preprocess, 8.2ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 11.3ms\n",
            "Speed: 2.9ms preprocess, 11.3ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 10.7ms\n",
            "Speed: 3.1ms preprocess, 10.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 7.5ms\n",
            "Speed: 2.9ms preprocess, 7.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 7.0ms\n",
            "Speed: 2.9ms preprocess, 7.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 8.8ms\n",
            "Speed: 3.1ms preprocess, 8.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 9.8ms\n",
            "Speed: 3.0ms preprocess, 9.8ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 8.1ms\n",
            "Speed: 3.0ms preprocess, 8.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 14.5ms\n",
            "Speed: 2.9ms preprocess, 14.5ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 16.7ms\n",
            "Speed: 2.9ms preprocess, 16.7ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 9.8ms\n",
            "Speed: 5.1ms preprocess, 9.8ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 13.9ms\n",
            "Speed: 4.4ms preprocess, 13.9ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 12.5ms\n",
            "Speed: 2.9ms preprocess, 12.5ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 14.7ms\n",
            "Speed: 4.8ms preprocess, 14.7ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 9.5ms\n",
            "Speed: 5.5ms preprocess, 9.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 10.8ms\n",
            "Speed: 3.4ms preprocess, 10.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 8.0ms\n",
            "Speed: 3.7ms preprocess, 8.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 10.7ms\n",
            "Speed: 2.9ms preprocess, 10.7ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 10.5ms\n",
            "Speed: 3.3ms preprocess, 10.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 9.1ms\n",
            "Speed: 3.6ms preprocess, 9.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 8.6ms\n",
            "Speed: 3.0ms preprocess, 8.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 12.2ms\n",
            "Speed: 3.5ms preprocess, 12.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 13.0ms\n",
            "Speed: 4.2ms preprocess, 13.0ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 9.8ms\n",
            "Speed: 3.2ms preprocess, 9.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 10.0ms\n",
            "Speed: 3.1ms preprocess, 10.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 10.9ms\n",
            "Speed: 3.3ms preprocess, 10.9ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 10.0ms\n",
            "Speed: 3.3ms preprocess, 10.0ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 8.3ms\n",
            "Speed: 3.1ms preprocess, 8.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 16.4ms\n",
            "Speed: 3.0ms preprocess, 16.4ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 15.8ms\n",
            "Speed: 3.4ms preprocess, 15.8ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 10.2ms\n",
            "Speed: 3.3ms preprocess, 10.2ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 14.3ms\n",
            "Speed: 4.1ms preprocess, 14.3ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 12.6ms\n",
            "Speed: 3.3ms preprocess, 12.6ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 10.2ms\n",
            "Speed: 3.7ms preprocess, 10.2ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 11.2ms\n",
            "Speed: 3.5ms preprocess, 11.2ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 8.0ms\n",
            "Speed: 2.8ms preprocess, 8.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 9.9ms\n",
            "Speed: 3.2ms preprocess, 9.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 10.4ms\n",
            "Speed: 2.8ms preprocess, 10.4ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 8.7ms\n",
            "Speed: 2.9ms preprocess, 8.7ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 7.2ms\n",
            "Speed: 3.9ms preprocess, 7.2ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 8.9ms\n",
            "Speed: 3.3ms preprocess, 8.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 10.5ms\n",
            "Speed: 2.7ms preprocess, 10.5ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 8.6ms\n",
            "Speed: 3.0ms preprocess, 8.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 8.4ms\n",
            "Speed: 2.9ms preprocess, 8.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 8.0ms\n",
            "Speed: 3.0ms preprocess, 8.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 12.4ms\n",
            "Speed: 2.9ms preprocess, 12.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 8.7ms\n",
            "Speed: 3.0ms preprocess, 8.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 11.0ms\n",
            "Speed: 3.0ms preprocess, 11.0ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 19.4ms\n",
            "Speed: 3.8ms preprocess, 19.4ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 10.3ms\n",
            "Speed: 8.5ms preprocess, 10.3ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 14.2ms\n",
            "Speed: 4.5ms preprocess, 14.2ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 12.8ms\n",
            "Speed: 6.0ms preprocess, 12.8ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 8.0ms\n",
            "Speed: 2.9ms preprocess, 8.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 9.7ms\n",
            "Speed: 3.2ms preprocess, 9.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 9.7ms\n",
            "Speed: 3.1ms preprocess, 9.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 9.4ms\n",
            "Speed: 3.0ms preprocess, 9.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 11.9ms\n",
            "Speed: 3.6ms preprocess, 11.9ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 8.2ms\n",
            "Speed: 3.1ms preprocess, 8.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 7.6ms\n",
            "Speed: 3.1ms preprocess, 7.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 9.6ms\n",
            "Speed: 2.8ms preprocess, 9.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 8.5ms\n",
            "Speed: 3.1ms preprocess, 8.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 9.0ms\n",
            "Speed: 2.9ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 10.5ms\n",
            "Speed: 3.2ms preprocess, 10.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 8.7ms\n",
            "Speed: 3.0ms preprocess, 8.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 9.6ms\n",
            "Speed: 3.0ms preprocess, 9.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 7.1ms\n",
            "Speed: 2.6ms preprocess, 7.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 6.9ms\n",
            "Speed: 3.0ms preprocess, 6.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 10.1ms\n",
            "Speed: 3.9ms preprocess, 10.1ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 helmets, 14.8ms\n",
            "Speed: 4.3ms preprocess, 14.8ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}